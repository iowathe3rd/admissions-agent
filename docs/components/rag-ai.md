# üß† RAG —Å–∏—Å—Ç–µ–º–∞ –∏ AI

–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã Retrieval-Augmented Generation (RAG) –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Google Gemini AI.

## –û–±–∑–æ—Ä RAG —Å–∏—Å—Ç–µ–º—ã

RAG —Å–∏—Å—Ç–µ–º–∞ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è —Ç–æ—á–Ω—ã–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.

```mermaid
graph TB
    Question[‚ùì –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è] --> Embedding[üî§ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞]
    Embedding --> Search[üîç –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫]
    Search --> VectorDB[(üìä ChromaDB)]
    VectorDB --> Context[üìù –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã]
    Context --> Prompt[üìã –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞]
    Prompt --> Gemini[üîÆ Google Gemini]
    Gemini --> Response[üí¨ –ì–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç]
    Response --> Postprocess[‚öôÔ∏è –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞]
    Postprocess --> User[üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å]
```

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ RAG —Å–∏—Å—Ç–µ–º—ã

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã

```
src/rag/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ genai.py              # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Google Gemini
‚îú‚îÄ‚îÄ retriever.py          # –ü–æ–∏—Å–∫ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
‚îú‚îÄ‚îÄ ingest.py            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
‚îú‚îÄ‚îÄ embeddings.py        # –†–∞–±–æ—Ç–∞ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
‚îú‚îÄ‚îÄ prompts.py           # –®–∞–±–ª–æ–Ω—ã –ø—Ä–æ–º–ø—Ç–æ–≤
‚îî‚îÄ‚îÄ index/               # –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
```

## 1. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (`ingest.py`)

### –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

```python
import json
import logging
from pathlib import Path
from typing import List, Dict, Any
import chromadb
from chromadb.config import Settings
import google.genai as genai

from app.config import settings

logger = logging.getLogger(__name__)

class DataIngestor:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É."""
    
    def __init__(self):
        self.client = chromadb.PersistentClient(
            path=settings.CHROMA_PERSIST_DIRECTORY,
            settings=Settings(anonymized_telemetry=False)
        )
        
        self.collection = self.client.get_or_create_collection(
            name=settings.CHROMA_COLLECTION_NAME,
            metadata={"description": "Admissions knowledge base"}
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self.genai_client = genai.Client(api_key=settings.GEMINI_API_KEY)

    async def ingest_data(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö."""
        
        logger.info("üîÑ –ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö...")
        
        try:
            # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
            self.collection.delete()
            
            # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
            await self._ingest_programs()
            await self._ingest_faqs()
            await self._ingest_steps()
            await self._ingest_documents()
            
            logger.info("‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
            raise

    async def _ingest_programs(self):
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º –æ–±—É—á–µ–Ω–∏—è."""
        
        programs_file = Path("src/data/seed/programs.json")
        
        if not programs_file.exists():
            logger.warning("–§–∞–π–ª programs.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        with open(programs_file, 'r', encoding='utf-8') as f:
            programs = json.load(f)
        
        documents = []
        metadatas = []
        ids = []
        
        for program in programs:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            text = self._format_program_text(program)
            
            documents.append(text)
            metadatas.append({
                "type": "program",
                "id": program["id"],
                "name": program["name"],
                "category": program.get("category", "unknown")
            })
            ids.append(f"program_{program['id']}")
        
        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        embeddings = await self._create_embeddings(documents)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
        self.collection.add(
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
        
        logger.info(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(programs)} –ø—Ä–æ–≥—Ä–∞–º–º")

    async def _ingest_faqs(self):
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è FAQ."""
        
        faqs_file = Path("src/data/seed/faqs.json")
        
        with open(faqs_file, 'r', encoding='utf-8') as f:
            faqs = json.load(f)
        
        documents = []
        metadatas = []
        ids = []
        
        for faq in faqs:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç: –≤–æ–ø—Ä–æ—Å + –æ—Ç–≤–µ—Ç
            text = f"–í–æ–ø—Ä–æ—Å: {faq['question']}\n–û—Ç–≤–µ—Ç: {faq['answer']}"
            
            documents.append(text)
            metadatas.append({
                "type": "faq",
                "id": faq["id"],
                "category": faq.get("category", "general"),
                "keywords": faq.get("keywords", [])
            })
            ids.append(f"faq_{faq['id']}")
        
        embeddings = await self._create_embeddings(documents)
        
        self.collection.add(
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
        
        logger.info(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(faqs)} FAQ")

    def _format_program_text(self, program: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º—É –≤ —Ç–µ–∫—Å—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."""
        
        text_parts = [
            f"–ü—Ä–æ–≥—Ä–∞–º–º–∞: {program['name']}",
            f"–û–ø–∏—Å–∞–Ω–∏–µ: {program.get('description', '')}",
            f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {program.get('duration', '')}",
            f"–°—Ç–æ–∏–º–æ—Å—Ç—å: {program.get('cost', '')} —Ä—É–±–ª–µ–π",
        ]
        
        if program.get('requirements'):
            requirements = ', '.join(program['requirements'])
            text_parts.append(f"–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: {requirements}")
        
        if program.get('career_prospects'):
            text_parts.append(f"–ö–∞—Ä—å–µ—Ä–Ω—ã–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã: {program['career_prospects']}")
        
        return '\n'.join(text_parts)

    async def _create_embeddings(self, texts: List[str]) -> List[List[float]]:
        """–°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤."""
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Gemini –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embeddings = []
            
            for text in texts:
                response = await self.genai_client.aembed_content(
                    model=settings.GEMINI_EMBEDDING_MODEL,
                    content=text
                )
                embeddings.append(response.embedding)
            
            return embeddings
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            raise

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
async def ingest_data():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö."""
    
    ingestor = DataIngestor()
    await ingestor.ingest_data()
```

## 2. –ü–æ–∏—Å–∫ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ (`retriever.py`)

### –°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

```python
import logging
from typing import List, Dict, Any, Optional
import chromadb
from chromadb.config import Settings
import google.genai as genai

from app.config import settings

logger = logging.getLogger(__name__)

class ContextRetriever:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
    
    def __init__(self):
        self.client = chromadb.PersistentClient(
            path=settings.CHROMA_PERSIST_DIRECTORY,
            settings=Settings(anonymized_telemetry=False)
        )
        
        try:
            self.collection = self.client.get_collection(
                name=settings.CHROMA_COLLECTION_NAME
            )
        except ValueError:
            logger.error("–ö–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö.")
            self.collection = None
        
        self.genai_client = genai.Client(api_key=settings.GEMINI_API_KEY)

    async def retrieve_context(
        self,
        query: str,
        max_chunks: int = 5,
        similarity_threshold: float = 0.3,
        filters: Optional[Dict[str, str]] = None
    ) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞.
        
        Args:
            query: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å
            max_chunks: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
            similarity_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏
            filters: –§–∏–ª—å—Ç—Ä—ã –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        
        if not self.collection:
            logger.error("–ö–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            return []
        
        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = await self._create_query_embedding(query)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=max_chunks * 2,  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                where=filters or {},
                include=["documents", "metadatas", "distances"]
            )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            context_chunks = self._process_search_results(
                results, 
                similarity_threshold,
                max_chunks
            )
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(context_chunks)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
            
            return context_chunks
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
            return []

    async def _create_query_embedding(self, query: str) -> List[float]:
        """–°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""
        
        try:
            response = await self.genai_client.aembed_content(
                model=settings.GEMINI_EMBEDDING_MODEL,
                content=query
            )
            return response.embedding
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            raise

    def _process_search_results(
        self,
        results: Dict[str, Any],
        similarity_threshold: float,
        max_chunks: int
    ) -> List[Dict[str, Any]]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞."""
        
        if not results['documents'] or not results['documents'][0]:
            return []
        
        documents = results['documents'][0]
        metadatas = results['metadatas'][0]
        distances = results['distances'][0]
        
        context_chunks = []
        
        for doc, metadata, distance in zip(documents, metadatas, distances):
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ —Å—Ö–æ–∂–µ—Å—Ç—å (cosine similarity)
            similarity = 1 - distance
            
            if similarity >= similarity_threshold:
                context_chunks.append({
                    'content': doc,
                    'metadata': metadata,
                    'similarity': similarity,
                    'source': self._get_source_info(metadata)
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        context_chunks.sort(key=lambda x: x['similarity'], reverse=True)
        
        return context_chunks[:max_chunks]

    def _get_source_info(self, metadata: Dict[str, Any]) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞."""
        
        doc_type = metadata.get('type', 'unknown')
        
        if doc_type == 'program':
            return f"–ü—Ä–æ–≥—Ä–∞–º–º–∞: {metadata.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è')}"
        elif doc_type == 'faq':
            return "FAQ"
        elif doc_type == 'step':
            return "–®–∞–≥–∏ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è"
        elif doc_type == 'document':
            return "–î–æ–∫—É–º–µ–Ω—Ç—ã"
        else:
            return "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π"

# –§—É–Ω–∫—Ü–∏–∏-—É—Ç–∏–ª–∏—Ç—ã
async def retrieve_context(query: str, **kwargs) -> List[Dict[str, Any]]:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
    
    retriever = ContextRetriever()
    return await retriever.retrieve_context(query, **kwargs)

def construct_prompt(query: str, context_chunks: List[Dict[str, Any]]) -> str:
    """–ö–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è AI –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
    
    if not context_chunks:
        return f"–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: {query}"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context_text = "\n\n".join([
        f"[{chunk['source']}]\n{chunk['content']}"
        for chunk in context_chunks
    ])
    
    prompt = f"""
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø—Ä–∏—ë–º–Ω–æ–π –∫–æ–º–∏—Å—Å–∏–∏ ALT University.

–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{query}

–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô:
{context_text}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –ö–û–ù–¢–ï–ö–°–¢–ê
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
3. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ
4. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã, –Ω–∞–∑–≤–∞–Ω–∏—è)
5. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø–æ–º–æ—â—å

–û—Ç–≤–µ—Ç:
    """
    
    return prompt
```

## 3. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Google Gemini (`genai.py`)

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤

```python
import google.genai as genai
from typing import Optional, Dict, Any
import logging
import asyncio

from app.config import settings

logger = logging.getLogger(__name__)

class GeminiClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Gemini API."""
    
    def __init__(self):
        self.client = genai.Client(api_key=settings.GEMINI_API_KEY)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.default_config = genai.GenerationConfig(
            temperature=0.3,
            top_p=0.8,
            top_k=40,
            max_output_tokens=1000,
        )

    async def generate_answer(
        self,
        prompt: str,
        model: str = None,
        config: Optional[genai.GenerationConfig] = None,
        safety_settings: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞.
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            config: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            safety_settings: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        
        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        """
        
        model = model or settings.GEMINI_DEFAULT_MODEL
        config = config or self.default_config
        
        try:
            response = await self.client.agenerate_content(
                model=model,
                contents=prompt,
                config=config,
                safety_settings=safety_settings or self._get_default_safety_settings()
            )
            
            if response.candidates:
                answer = response.candidates[0].content.parts[0].text
                return self._post_process_answer(answer)
            else:
                logger.warning("Gemini –Ω–µ –≤–µ—Ä–Ω—É–ª –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤")
                return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç."
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return self._get_fallback_response()

    async def create_embedding(self, text: str, model: str = None) -> List[float]:
        """–°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞."""
        
        model = model or settings.GEMINI_EMBEDDING_MODEL
        
        try:
            response = await self.client.aembed_content(
                model=model,
                content=text
            )
            return response.embedding
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            raise

    def _get_default_safety_settings(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
        
        return {
            genai.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            genai.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            genai.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: genai.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            genai.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        }

    def _post_process_answer(self, answer: str) -> str:
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞."""
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        answer = answer.strip()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ –¥–ª—è Telegram
        max_length = 4000
        if len(answer) > max_length:
            answer = answer[:max_length - 3] + "..."
        
        # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        if not any(char for char in answer if ord(char) > 127):
            answer = "üí° " + answer
        
        return answer

    def _get_fallback_response(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ."""
        
        return (
            "ü§ñ –ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞.\n\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
            "‚Ä¢ –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å\n"
            "‚Ä¢ –í–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–µ–Ω—é –Ω–∞–≤–∏–≥–∞—Ü–∏–∏\n"
            "‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –ø—Ä–∏—ë–º–Ω—É—é –∫–æ–º–∏—Å—Å–∏—é\n\n"
            "üìû –ö–æ–Ω—Ç–∞–∫—Ç—ã: admissions@alt.university"
        )

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞
_gemini_client = None

def get_gemini_client() -> GeminiClient:
    """–ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä Gemini –∫–ª–∏–µ–Ω—Ç–∞."""
    
    global _gemini_client
    if _gemini_client is None:
        _gemini_client = GeminiClient()
    return _gemini_client

# –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def llm_answer(prompt: str, model: str = None) -> str:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM."""
    
    client = get_gemini_client()
    return await client.generate_answer(prompt, model)

async def create_embedding(text: str, model: str = None) -> List[float]:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞."""
    
    client = get_gemini_client()
    return await client.create_embedding(text, model)
```

## 4. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ RAG

### –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫

```python
class HybridRetriever(ContextRetriever):
    """–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫: –≤–µ–∫—Ç–æ—Ä–Ω—ã–π + —Ç–µ–∫—Å—Ç–æ–≤—ã–π."""
    
    def __init__(self):
        super().__init__()
        self.keyword_weights = {
            '–ø—Ä–æ–≥—Ä–∞–º–º—ã': 1.2,
            '—Å—Ç–æ–∏–º–æ—Å—Ç—å': 1.1,
            '–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ': 1.1,
            '–¥–æ–∫—É–º–µ–Ω—Ç—ã': 1.0,
        }

    async def hybrid_search(
        self,
        query: str,
        max_chunks: int = 5,
        vector_weight: float = 0.7,
        keyword_weight: float = 0.3
    ) -> List[Dict[str, Any]]:
        """–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–º–±–∏–Ω–∏—Ä—É—é—â–∏–π –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏ –∫–ª—é—á–µ–≤–æ–π –ø–æ–∏—Å–∫."""
        
        # –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
        vector_results = await self.retrieve_context(query, max_chunks * 2)
        
        # –ö–ª—é—á–µ–≤–æ–π –ø–æ–∏—Å–∫
        keyword_results = await self._keyword_search(query, max_chunks * 2)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        combined_results = self._combine_search_results(
            vector_results, 
            keyword_results,
            vector_weight,
            keyword_weight
        )
        
        return combined_results[:max_chunks]

    async def _keyword_search(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º."""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        keywords = self._extract_keywords(query.lower())
        
        # –ü–æ–∏—Å–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
        all_results = self.collection.get(
            include=["documents", "metadatas"]
        )
        
        scored_results = []
        
        for doc, metadata in zip(all_results['documents'], all_results['metadatas']):
            score = self._calculate_keyword_score(doc.lower(), keywords)
            
            if score > 0:
                scored_results.append({
                    'content': doc,
                    'metadata': metadata,
                    'similarity': score,
                    'source': self._get_source_info(metadata)
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        scored_results.sort(key=lambda x: x['similarity'], reverse=True)
        
        return scored_results[:max_results]

    def _extract_keywords(self, query: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞."""
        
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é NLP
        stop_words = {'–∫–∞–∫', '—á—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '—Å–∫–æ–ª—å–∫–æ', '–∫–∞–∫–∏–µ', '–∏', '–≤', '–Ω–∞', '—Å', '–ø–æ'}
        
        words = query.split()
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        
        return keywords

    def _calculate_keyword_score(self, text: str, keywords: List[str]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º."""
        
        score = 0.0
        
        for keyword in keywords:
            count = text.count(keyword)
            weight = self.keyword_weights.get(keyword, 1.0)
            score += count * weight
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞
        return score / (len(text.split()) + 1)
```

### –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤

```python
class QualityController:
    """–ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è RAG –æ—Ç–≤–µ—Ç–æ–≤."""
    
    def __init__(self):
        self.gemini_client = get_gemini_client()

    async def validate_answer(
        self,
        question: str,
        answer: str,
        context: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞."""
        
        validation_result = {
            'is_valid': True,
            'issues': [],
            'confidence': 1.0,
            'suggestions': []
        }
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏
        hallucination_check = await self._check_hallucinations(answer, context)
        if not hallucination_check['passed']:
            validation_result['is_valid'] = False
            validation_result['issues'].append('potential_hallucination')
            validation_result['confidence'] *= 0.5
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        relevance_score = await self._check_relevance(question, answer)
        if relevance_score < 0.6:
            validation_result['issues'].append('low_relevance')
            validation_result['confidence'] *= 0.7
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã
        completeness_score = self._check_completeness(question, answer)
        if completeness_score < 0.5:
            validation_result['issues'].append('incomplete_answer')
            validation_result['suggestions'].append('–û—Ç–≤–µ—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º')
        
        return validation_result

    async def _check_hallucinations(
        self,
        answer: str,
        context: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏."""
        
        context_text = '\n'.join([chunk['content'] for chunk in context])
        
        prompt = f"""
–ü—Ä–æ–≤–µ—Ä—å, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –û–¢–í–ï–¢ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç –≤ –ö–û–ù–¢–ï–ö–°–¢–ï.

–ö–û–ù–¢–ï–ö–°–¢:
{context_text}

–û–¢–í–ï–¢:
{answer}

–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ '–î–ê' –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, –∏–ª–∏ '–ù–ï–¢' –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—ã–¥—É–º–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
        """
        
        try:
            response = await self.gemini_client.generate_answer(prompt)
            passed = '–¥–∞' in response.lower()
            
            return {
                'passed': passed,
                'details': response
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π: {e}")
            return {'passed': True, 'details': '–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞'}

    async def _check_relevance(self, question: str, answer: str) -> float:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –≤–æ–ø—Ä–æ—Å—É."""
        
        prompt = f"""
–û—Ü–µ–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –û–¢–í–ï–¢–ê –∫ –í–û–ü–†–û–°–£ –ø–æ —à–∫–∞–ª–µ –æ—Ç 0 –¥–æ 1.

–í–û–ü–†–û–°: {question}
–û–¢–í–ï–¢: {answer}

–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–º –æ—Ç 0.0 –¥–æ 1.0.
        """
        
        try:
            response = await self.gemini_client.generate_answer(prompt)
            score = float(response.strip())
            return max(0.0, min(1.0, score))
            
        except (ValueError, Exception):
            return 0.8  # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
```

## 5. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏ RAG

### –°–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫

```python
import time
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class RAGMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RAG —Å–∏—Å—Ç–µ–º—ã."""
    
    query_count: int = 0
    avg_response_time: float = 0.0
    avg_context_chunks: float = 0.0
    avg_similarity_score: float = 0.0
    success_rate: float = 0.0
    error_count: int = 0
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    user_satisfaction: float = 0.0
    answer_relevance: float = 0.0
    hallucination_rate: float = 0.0

class RAGMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ RAG —Å–∏—Å—Ç–µ–º—ã."""
    
    def __init__(self):
        self.metrics = RAGMetrics()
        self.query_history = []
        self.start_time = datetime.now()

    async def log_query(
        self,
        query: str,
        response: str,
        context_chunks: List[Dict[str, Any]],
        response_time: float,
        success: bool = True
    ):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞."""
        
        entry = {
            'timestamp': datetime.now().isoformat(),
            'query': query,
            'response': response,
            'context_chunks_count': len(context_chunks),
            'avg_similarity': sum(c.get('similarity', 0) for c in context_chunks) / len(context_chunks) if context_chunks else 0,
            'response_time': response_time,
            'success': success
        }
        
        self.query_history.append(entry)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        await self._update_metrics()

    async def _update_metrics(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏."""
        
        if not self.query_history:
            return
        
        recent_queries = [
            q for q in self.query_history
            if datetime.fromisoformat(q['timestamp']) > datetime.now() - timedelta(hours=24)
        ]
        
        if not recent_queries:
            return
        
        self.metrics.query_count = len(recent_queries)
        self.metrics.avg_response_time = sum(q['response_time'] for q in recent_queries) / len(recent_queries)
        self.metrics.avg_context_chunks = sum(q['context_chunks_count'] for q in recent_queries) / len(recent_queries)
        self.metrics.avg_similarity_score = sum(q['avg_similarity'] for q in recent_queries) / len(recent_queries)
        self.metrics.success_rate = sum(1 for q in recent_queries if q['success']) / len(recent_queries)
        self.metrics.error_count = sum(1 for q in recent_queries if not q['success'])

    def get_performance_report(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        
        uptime = (datetime.now() - self.start_time).total_seconds() / 3600  # –≤ —á–∞—Å–∞—Ö
        
        return {
            'uptime_hours': round(uptime, 2),
            'total_queries': len(self.query_history),
            'recent_24h_metrics': {
                'query_count': self.metrics.query_count,
                'avg_response_time': round(self.metrics.avg_response_time, 3),
                'avg_context_chunks': round(self.metrics.avg_context_chunks, 2),
                'avg_similarity_score': round(self.metrics.avg_similarity_score, 3),
                'success_rate': round(self.metrics.success_rate, 3),
                'error_count': self.metrics.error_count
            },
            'system_health': self._assess_system_health()
        }

    def _assess_system_health(self) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã."""
        
        if self.metrics.success_rate >= 0.95 and self.metrics.avg_response_time < 2.0:
            return "excellent"
        elif self.metrics.success_rate >= 0.90 and self.metrics.avg_response_time < 3.0:
            return "good"
        elif self.metrics.success_rate >= 0.80:
            return "fair"
        else:
            return "poor"

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä
rag_monitor = RAGMonitor()
```

## 6. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

```python
# –í config.py
class RAGSettings:
    # –ü–æ–∏—Å–∫
    MAX_CONTEXT_CHUNKS: int = 5
    SIMILARITY_THRESHOLD: float = 0.3
    CHUNK_SIZE: int = 1000
    CHUNK_OVERLAP: int = 200
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    TEMPERATURE: float = 0.3
    MAX_OUTPUT_TOKENS: int = 1000
    TOP_P: float = 0.8
    TOP_K: int = 40
    
    # –ú–æ–¥–µ–ª–∏
    DEFAULT_MODEL: str = "gemini-2.0-flash-exp"
    PRO_MODEL: str = "gemini-2.0-pro-exp"
    EMBEDDING_MODEL: str = "text-embedding-004"
    
    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    CACHE_TTL: int = 300  # 5 –º–∏–Ω—É—Ç
    MAX_CONCURRENT_REQUESTS: int = 10
    RETRY_ATTEMPTS: int = 3
    
    # –ö–∞—á–µ—Å—Ç–≤–æ
    ENABLE_QUALITY_CHECK: bool = True
    HALLUCINATION_CHECK: bool = True
    MIN_RELEVANCE_SCORE: float = 0.6
```

### –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
import hashlib
from typing import Optional
import redis
import json

class RAGCache:
    """–ö–µ—à –¥–ª—è RAG –æ—Ç–≤–µ—Ç–æ–≤."""
    
    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis_client = redis.from_url(redis_url)
        self.ttl = settings.CACHE_TTL

    def _generate_cache_key(self, query: str, context_hash: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫–µ—à–∞."""
        
        combined = f"{query}:{context_hash}"
        return f"rag_cache:{hashlib.md5(combined.encode()).hexdigest()}"

    def _hash_context(self, context_chunks: List[Dict[str, Any]]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ö–µ—à –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
        
        context_str = json.dumps([c['content'] for c in context_chunks], sort_keys=True)
        return hashlib.md5(context_str.encode()).hexdigest()

    async def get_cached_response(
        self,
        query: str,
        context_chunks: List[Dict[str, Any]]
    ) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç."""
        
        try:
            context_hash = self._hash_context(context_chunks)
            cache_key = self._generate_cache_key(query, context_hash)
            
            cached_response = self.redis_client.get(cache_key)
            if cached_response:
                return cached_response.decode('utf-8')
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–∑ –∫–µ—à–∞: {e}")
        
        return None

    async def cache_response(
        self,
        query: str,
        context_chunks: List[Dict[str, Any]],
        response: str
    ):
        """–ö–µ—à–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç."""
        
        try:
            context_hash = self._hash_context(context_chunks)
            cache_key = self._generate_cache_key(query, context_hash)
            
            self.redis_client.setex(
                cache_key,
                self.ttl,
                response.encode('utf-8')
            )
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –∫–µ—à: {e}")
```

–≠—Ç–∞ RAG —Å–∏—Å—Ç–µ–º–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
- **–¢–æ—á–Ω–æ—Å—Ç—å**: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- **–ö–∞—á–µ—Å—Ç–≤–æ**: –ö–æ–Ω—Ç—Ä–æ–ª—å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤
- **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥**: –î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤